# Trajectory Synthetic Data Generator

A production-ready system for generating high-quality training data for Small Language Models (SLMs) using trajectory-based synthetic data generation with multi-iteration reasoning patterns.

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![AWS Bedrock](https://img.shields.io/badge/AWS-Bedrock-orange.svg)](https://aws.amazon.com/bedrock/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ What This Does

Generates **thousands of training examples** from a small set of seed queries through:
- **Multi-iteration reasoning trajectories** (CALL â†’ CALL â†’ ANSWER patterns)
- **30Ã— query expansion** via persona/complexity/tool transformations
- **Document-based Q&A generation** from PDF knowledge bases
- **Stateless iterative reasoning** teaching when to use tools, ask questions, or answer

**Input:** 10 seed queries  
**Output:** 300-900 training examples in `{Q, COT, Tool Set, Decision}` format

---

## âš¡ Quick Start
```bash
# 1. Clone and setup
git clone https://github.com/vishal2002series1/synthetic-data-kit-with-trajectory.git
cd synthetic-data-kit-with-trajectory
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# 2. Configure AWS credentials
export AWS_REGION=us-east-1
export AWS_ACCESS_KEY_ID=your_key
export AWS_SECRET_ACCESS_KEY=your_secret

# 3. Add PDFs and run complete pipeline
mkdir -p data/pdfs
cp your_pdfs/*.pdf data/pdfs/
./scripts/complete_pipeline_with_ingest.sh 20

# Output: samples/pipeline_TIMESTAMP/04_trajectories.jsonl
```

See [QUICKSTART.md](docs/QUICKSTART.md) for detailed setup.

---

## ğŸ“Š Key Features

### ğŸ“ Training Data Generation
- **Multi-iteration trajectories**: 1-3 reasoning steps per query
- **Decision patterns**: CALL (use tools), ASK (clarify), ANSWER (respond)
- **Chain-of-thought reasoning**: High-quality COT for each iteration
- **Tool orchestration**: Teaches SLMs when/how to use tools

### ğŸ”„ 30Ã— Query Expansion
- **5 Personas**: First-time investor, Professional, Technical analyst, Anxious investor, Executive
- **3 Complexity levels**: Simplified (Q-), Original (Q), Complex (Q+)
- **2 Tool variants**: Correct data, Incorrect data (error handling)
- **Total**: 5 Ã— 3 Ã— 2 = **30Ã— expansion per seed**

### ğŸ“š Document Processing
- **PDF ingestion**: Multi-modal parsing with text + vision
- **ChromaDB vector storage**: Persistent embeddings
- **Smart chunking**: 4000 tokens with 200 overlap
- **Q&A generation**: Extract questions from documents

### ğŸ› ï¸ Production Ready
- **Complete CLI**: 7 commands for full workflow
- **Quality validation**: Format, diversity, quality checks
- **Progress tracking**: Real-time progress bars
- **Error handling**: Robust error recovery

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INPUT SOURCES                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PDFs (data/pdfs/)          Seed Queries (data/seed/)       â”‚
â”‚       â”‚                              â”‚                       â”‚
â”‚       â–¼                              â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Ingest  â”‚                   â”‚ Manual   â”‚                â”‚
â”‚  â”‚ PDFs    â”‚                   â”‚ Seeds    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚
â”‚       â”‚                              â”‚                       â”‚
â”‚       â–¼                              â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                       â”‚
â”‚  â”‚   VectorDB      â”‚                â”‚                       â”‚
â”‚  â”‚  (ChromaDB)     â”‚                â”‚                       â”‚
â”‚  â”‚  291 documents  â”‚                â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                       â”‚
â”‚       â”‚                              â”‚                       â”‚
â”‚       â–¼                              â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                       â”‚
â”‚  â”‚ Q&A Generator   â”‚                â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                       â”‚
â”‚       â”‚                              â”‚                       â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚     TRANSFORMATION PIPELINE          â”‚                   â”‚
â”‚  â”‚  (30Ã— Expansion)                     â”‚                   â”‚
â”‚  â”‚                                      â”‚                   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚  â”‚  â”‚  Persona Transformer (5Ã—)    â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚  P1-P5 variants              â”‚  â”‚                   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚  â”‚               â–¼                     â”‚                   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚  â”‚  â”‚  Query Modifier (3Ã—)         â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚  Q-, Q, Q+ complexity        â”‚  â”‚                   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚  â”‚               â–¼                     â”‚                   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚  â”‚  â”‚  Tool Data Transformer (2Ã—)  â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚  correct/incorrect variants  â”‚  â”‚                   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                  â”‚                                          â”‚
â”‚                  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚   TRAJECTORY GENERATOR               â”‚                   â”‚
â”‚  â”‚   (Multi-iteration)                  â”‚                   â”‚
â”‚  â”‚                                      â”‚                   â”‚
â”‚  â”‚  Iteration 0: CALL â†’ gather info    â”‚                   â”‚
â”‚  â”‚  Iteration 1: CALL â†’ more analysis  â”‚                   â”‚
â”‚  â”‚  Iteration 2: ANSWER â†’ final result â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚               â”‚                                             â”‚
â”‚               â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚      TRAINING EXAMPLES               â”‚                   â”‚
â”‚  â”‚  {Q, COT, Tool Set, Decision}       â”‚                   â”‚
â”‚  â”‚                                      â”‚                   â”‚
â”‚  â”‚  â€¢ 300-900 examples from 10 seeds   â”‚                   â”‚
â”‚  â”‚  â€¢ Multi-iteration reasoning         â”‚                   â”‚
â”‚  â”‚  â€¢ Tool usage patterns              â”‚                   â”‚
â”‚  â”‚  â€¢ Decision making logic            â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed design.

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [QUICKSTART.md](docs/QUICKSTART.md) | 5-minute setup guide |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | System design & components |
| [API_REFERENCE.md](docs/API_REFERENCE.md) | CLI commands & usage |
| [EXAMPLES.md](docs/EXAMPLES.md) | Real-world examples |
| [FAQ.md](docs/FAQ.md) | Troubleshooting & tips |
| [VISION_ENHANCEMENT.md](docs/VISION_ENHANCEMENT.md) | Future vision roadmap |

---

## ğŸ¯ Training Data Format

Each training example teaches SLMs **when to take action**:
```json
{
  "Q": "How should I optimize my portfolio for retirement?",
  "COT": "The user needs portfolio optimization guidance. I should first analyze their current risk profile, then suggest allocation strategies...",
  "Tool Set": [
    {
      "name": "analyze_portfolio_risk",
      "description": "Analyze portfolio risk metrics",
      "parameters": {"client_id": "...", "lookback_period": "3Y"}
    }
  ],
  "Decision": "CALL",
  "metadata": {"iteration": 0, "decision_type": "CALL"}
}
```

**Decision Types:**
- `CALL`: Execute tools to gather information
- `ASK: <question>`: Request user clarification
- `ANSWER: <response>`: Provide final answer

---

## ğŸš€ Usage

### Complete Pipeline (Recommended)
```bash
# Generate everything: Q&A â†’ Transformations â†’ Trajectories
./scripts/complete_pipeline_with_ingest.sh data/pdfs 20

# Output: 20 Q&A â†’ 600 transformations â†’ 600-1800 training examples
```

### Individual Commands
```bash
# 1. Ingest PDFs
python main.py ingest-batch data/pdfs/

# 2. Generate Q&A from documents
python main.py generate-qa --limit 50 --output samples/qa.jsonl

# 3. Transform queries (30Ã— expansion)
python main.py transform queries.json --output samples/transformed.jsonl

# 4. Generate trajectories
python main.py generate queries.json --output samples/trajectories.jsonl

# 5. View statistics
python main.py stats
```

See [API_REFERENCE.md](docs/API_REFERENCE.md) for all commands.

---

## ğŸ“Š Results

**From 3 seed queries:**
- âœ… 90 transformed queries (30Ã— expansion)
- âœ… 150+ training examples (multi-iteration)
- âœ… CALL â†’ CALL â†’ ANSWER patterns
- âœ… High-quality chain-of-thought reasoning

**From 20 Q&A pairs:**
- âœ… 600 transformed queries
- âœ… 600-1,800 training examples
- âœ… Ready for SLM fine-tuning

---

## ğŸ”§ Configuration

Edit `config/config.yaml`:
```yaml
bedrock:
  model_id: "anthropic.claude-sonnet-4-20250514-v1:0"
  region: "us-east-1"
  max_tokens: 64000

pdf_processing:
  chunk_size: 4000
  chunk_overlap: 200
  use_vision_for_images: true

output:
  format: "jsonl"
  fields:
    query: "Q"
    cot: "COT"
    tools: "Tool Set"
    decision: "Decision"
```

---

## ğŸ§ª Quality Validation
```bash
# Validate format
python scripts/validate_format.py samples/trajectories.jsonl

# Analyze quality
python scripts/analyze_quality.py samples/trajectories.jsonl

# Check diversity
python scripts/check_diversity.py samples/transformed.jsonl

# Overall summary
python scripts/summarize_dataset.py
```

---

## ğŸ“ Use Cases

### 1. Fine-tuning Small Language Models
Train models to:
- Decide when to use tools vs. answer directly
- Chain multiple tool calls for complex tasks
- Ask clarifying questions when needed
- Generate reasoning before acting

### 2. Conversational AI Training
- Multi-turn dialogue patterns
- Context accumulation across turns
- Tool-augmented responses

### 3. Research & Experimentation
- Test different reasoning patterns
- Evaluate decision-making strategies
- Benchmark SLM performance

---

## ğŸ“ˆ Expansion Capabilities

**Current:**
- 30Ã— per seed query (5 personas Ã— 3 complexity Ã— 2 tool variants)
- 1-3 training examples per transformed query
- **Total: 30-90Ã— effective expansion**

**Future (with Q- reduction):**
- 432Ã— per seed query (Q- iterative simplification)
- Policy knowledge base integration
- Enhanced vision analysis

---

## ğŸ”® Roadmap

- [x] Multi-iteration trajectory generation
- [x] 30Ã— query transformation
- [x] PDF ingestion with ChromaDB
- [x] Complete CLI interface
- [x] Quality validation tools
- [ ] Enhanced vision analysis (see [VISION_ENHANCEMENT.md](docs/VISION_ENHANCEMENT.md))
- [ ] Q- reduction system (432Ã— expansion)
- [ ] Policy knowledge base integration
- [ ] Distributed processing for scale

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:
- Vision analysis enhancement
- Additional transformation strategies
- Quality metrics & evaluation
- SLM fine-tuning examples

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) for details

---

## ğŸ™ Acknowledgments

- Built with AWS Bedrock (Claude Sonnet 4)
- ChromaDB for vector storage
- Inspired by trajectory-based reasoning research

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/vishal2002series1/synthetic-data-kit-with-trajectory/issues)
- **Documentation**: [docs/](docs/)
- **Examples**: [EXAMPLES.md](docs/EXAMPLES.md)

---

## ğŸ“Š Project Status

**Phase 8/8 Complete** âœ…

- âœ… Phase 1: Repository setup
- âœ… Phase 2: Core components
- âœ… Phase 3: Q&A generation
- âœ… Phase 4: Multi-iteration trajectories
- âœ… Phase 5: Transformations (30Ã— expansion)
- âœ… Phase 6: CLI integration
- âœ… Phase 7: Evaluation & samples
- âœ… Phase 8: Documentation

**Status:** Production Ready ğŸš€

---

*Built for generating high-quality training data for Small Language Models*
